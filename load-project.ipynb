{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MLRun Projects and GIT\n",
    "  --------------------------------------------------------------------\n",
    "\n",
    "Loading or creating a full project with multiple functions and workflow and working wit Git.\n",
    "\n",
    "#### **notebook how-to's**\n",
    "* Load a project with multiple functions from Git\n",
    "* Run automated workflows (using KubeFlow)\n",
    "* Update, maintain and debug code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "#### **steps**\n",
    "**[Load project from Git or Archive](#load-project)**<br>\n",
    "**[Run a pipeline workflow](#run-pipeline)**<br>\n",
    "**[Updating the project and code](#update-project)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import load_project, code_to_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-project'></a>\n",
    "## Load project from Git or Archive\n",
    "\n",
    "Projects can be stored in a Git repo or in a tar archive (on object store like S3, V3IO).\n",
    "\n",
    "`load_project(context, url)` will load/clone the project to the local context dir and build the project object from the `project.yaml` file in the git/archive root directory. \n",
    "\n",
    "> Note: If URL is not specified it will use the context and search for Git repo inside it, or use the `init_git=True` flag to initialize a Git repo in the target context directory.\n",
    "\n",
    "You can also clone the code into a dir using a CLI commands:\n",
    "\n",
    "`mlrun project my-proj/ -u git://github.com/mlrun/demo-xgb-project.git`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source Git Repo, YOU SHOULD fork this to your account and use the fork\n",
    "url = 'git://github.com/yjb-ds/demo-xgb-project.git'\n",
    "\n",
    "# alternatively can use tar files, e.g.\n",
    "#url = 'v3io:///users/admin/tars/src-project.tar.gz'\n",
    "\n",
    "project_dir = './'  # change if you want to clone into a different dir\n",
    "proj = load_project(project_dir, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir into the project dir if you are not running from it\n",
    "!cd {project_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'git://github.com/yjb-ds/demo-xgb-project.git#refs/heads/functions'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the project object, note it contains lists of `functions` and `workflows` which will be used in the project. Functions can be local to the project or referenced to (via a URL to .ipynb, .py, .yaml file and/or container image). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: train_xgb_classifier\n",
      "functions:\n",
      "- url: https://raw.githubusercontent.com/mlrun/functions/master/load_dataset/function.yaml\n",
      "  name: get_data\n",
      "- url: https://raw.githubusercontent.com/mlrun/functions/master/describe/function.yaml\n",
      "  name: summary\n",
      "- url: https://raw.githubusercontent.com/mlrun/functions/master/sklearn_classifier/function.yaml\n",
      "  name: train\n",
      "- url: https://raw.githubusercontent.com/mlrun/functions/master/test_classifier/function.yaml\n",
      "  name: test\n",
      "- url: https://raw.githubusercontent.com/mlrun/functions/master/serving/model_server.ipynb\n",
      "  name: server\n",
      "workflows:\n",
      "- name: main\n",
      "  code: workflow.py\n",
      "artifacts: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(proj.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='update-project'></a>\n",
    "## Updating the project and code\n",
    "\n",
    "A user can update the code using the standard Git process (commit, push, ..), if you update/edit the project object you need to run `proj.save()` which will update the `project.yaml` file in your context directory, followed by pushing your updates.\n",
    "\n",
    "You can use `proj.push(branch, commit_message, add=[])` which will do the work for you (save the yaml, commit updates, push)\n",
    "\n",
    "> Note: you must push updates before you build functions or run workflows since the builder will pull the code from the git repo.\n",
    "\n",
    "If you are using containerized Jupyter you may need to first set your Git parameters, e.g.:\n",
    "\n",
    "```\n",
    "!git config --global user.email \"<my@email.com>\"\n",
    "!git config --global user.name \"<name>\"\n",
    "!git config --global credential.helper store\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.push('functions', 'api changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to pull changes done by others use `proj.pull()`, if you need to update the project spec (since the yaml file changed) use `proj.reload()` and for updating the local/remote function specs use `proj.sync_functions()` (or add `sync=True` to `.reload()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj.pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-pipeline'></a>\n",
    "## Run a pipeline workflow\n",
    "You can check the [workflow.py](src/workflow.py) file to see how functions objects are initialized and used (by name) inside the workflow.\n",
    "The `workflow.py` file has two parts, initialize the function objects and define pipeline dsl (connect the function inputs and outputs).\n",
    "\n",
    "> Note the pipeline can include CI steps like building container images and deploying models.\n",
    "\n",
    "### Initializing the functions (e.g. mount them on the v3io fabric)\n",
    "```python\n",
    "def init_functions(functions: dict, params=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "```\n",
    "<br>\n",
    "\n",
    "### Workflow DSL:\n",
    "```python\n",
    "@dsl.pipeline(\n",
    "    name='My XGBoost training pipeline',\n",
    "    description='Shows how to use mlrun.'\n",
    ")\n",
    "def kfpipeline():\n",
    "    ingest = funcs['get_data'].as_step(\n",
    "        name='get data',\n",
    "        params={'dataset': DATASET},\n",
    "        outputs=[DATASET],\n",
    "        out_path=DATA_PATH)\n",
    "\n",
    "    describe = funcs['summary'].as_step(\n",
    "        name='summary',\n",
    "        params={\"key\": \"summary\", \"label_column\": LABELS},\n",
    "        inputs={\"table\": ingest.outputs[DATASET]},\n",
    "        outputs=[DATASET])\n",
    "    \n",
    "    configs = funcs['get_model_config'].as_step(\n",
    "        name='get model config',\n",
    "        params={'config': '/User/demo-xgb-project/XGBClassifier.json'},\n",
    "        outputs=['class_params', 'fit_params'])\n",
    "    \n",
    "    train = funcs['train'].as_step(\n",
    "        name='train',\n",
    "        params={'sample': -1, 'label_column': LABELS},\n",
    "        inputs={'data_key'    : ingest.outputs[DATASET],\n",
    "                'class_params': configs.outputs['class_params'],\n",
    "                'fit_params'  : configs.outputs['fit_params']},\n",
    "        outputs=['model', 'test_set'])\n",
    "\n",
    "    test = funcs['test'].as_step(\n",
    "        name='test',\n",
    "        params={'label_column': LABELS},\n",
    "        inputs={'models_dir'  : train.outputs['model'],\n",
    "                'test_set'    : train.outputs['test_set']},\n",
    "        outputs=['model'])\n",
    "\n",
    "    deploy = funcs['server'].deploy_step(\n",
    "       project=DATASET, \n",
    "       models={f'{DATASET}_v1': train.outputs['model']})\n",
    "```\n",
    "\n",
    "### Run\n",
    "use the `run` method to execute a workflow, you can provide alternative arguments and specify the default target for workflow artifacts.<br>\n",
    "The workflow ID is returned and can be used to track the progress or you can use the hyperlinks\n",
    "\n",
    "> Note: The same command can be issued through CLI commands:<br>\n",
    "    `mlrun project my-proj/ -r main -p \"v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/\"`\n",
    "\n",
    "The dirty flag allow us to run a project with uncommited changes (when the notebook is in the same git dir it will always be dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.conda/envs/stable/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/User/.conda/envs/stable/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/User/.conda/envs/stable/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/User/.conda/envs/stable/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.tgavrrspgjah.iguazio-cd2.com/pipelines/#/experiments/details/e43f5861-3681-4168-bc9d-4bee1a46b87f\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.tgavrrspgjah.iguazio-cd2.com/pipelines/#/runs/details/c2479d91-e5b5-44a5-b95b-8dda401d2c77\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-22 09:41:49,387 Pipeline run id=c2479d91-e5b5-44a5-b95b-8dda401d2c77, check UI or DB for progress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c2479d91-e5b5-44a5-b95b-8dda401d2c77'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    artifact_path=os.path.join('/User/demo-xgb-project','artifacts','{{workflow.uid}}'), \n",
    "    dirty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing the source path to speed debug\n",
    "\n",
    "Instead of updating Git anytime we modify code we can build the code from the shared file system on the cluster (the build container will mount to the same location with the code instead of reading from Git).\n",
    "\n",
    "We need to change the project source to point to the shared file system URL of our context directory (e.g. v3io), and we can re-run the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.source = 'v3io:///users/admin/my-proj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-v0.4.6",
   "language": "python",
   "name": "mlrun-v0.4.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
